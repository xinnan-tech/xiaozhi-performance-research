# A10显卡部署本地FunASR速度报告
NVIDIA A10显卡为FunASR提供近5倍的端到端加速，建议生产环境优先采用GPU方案部署。
# 测试结论
1.GPU显著加速：A10显卡相比CPU处理速度提升4-11倍，批量处理效率达20文件/秒
2.长音频优势明显：对60秒以上音频，GPU加速比达11.62倍
3.资源利用率高：RTF（实时因子）低至0.002-0.039，单音频处理最快仅0.049秒
# 机器配置
GPU	NVIDIA A10 (Ampere架构)	
  - CUDA核心数：9216	- FP32算力：31.2 TFLOPS
  - 显存容量：24GB GDDR6 (实际可用23028 MiB)	- 显存带宽：600 GB/s
  - 基础频率：1695 MHz / 加速频率：1695 MHz	- 功耗限制：150W (可调范围100-150W)
  - PCIe 4.0 x16 (实测带宽16x)	- 支持ECC：已启用
CPU	Intel Xeon Platinum 8369B	
  - 核心数：16核32线程	- L3缓存：48MB
  - 基础频率：2.9 GHz 	- 支持AVX-512指令集
  - 架构：Ice Lake (10nm)	- TDP：270W
内存
  - 总容量：181GB DDR4	
软件环境
  - PyTorch：2.5.1+cu121	- CUDA版本：12.1
  - FunASR：1.2.6	- 驱动版本：570.169
# 测试过程
1.使用Python 3.10.18搭建相关环境，安装FunASR1.2.6版本
2.多模式下使用CPU和GPU进行测试
测试数据集
    文件	        时长	     内容类型
    asr_test.wav	~3s	         - 日常问答
    asr_test8.mp3	~60s	     - 歌曲《起风了》
    ...（共9个文件） 总计~120s	   - 包含对话/故事/歌曲
### 测试代码
import time
import argparse
from funasr import AutoModel
import torch
import os
import glob
import re


def clean_asr_result(text):
    """清理ASR结果中的标签"""
    return re.sub(r'<\|.*?\|>', '', text).strip()


def test_asr_performance(audio_files, model_path, use_gpu=False, batch_mode=False):
    """测试ASR性能并返回结果和耗时"""

    # 初始化模型配置
    model_kwargs = {
        "model": model_path,
        "vad_kwargs": {"max_single_segment_time": 30000},
        "disable_update": True,
        "hub": "hf"
    }

    device = "cuda:0" if use_gpu else "cpu"
    model_kwargs["device"] = device
    print(f"\n正在初始化模型，使用设备: {device}{' (批量模式)' if batch_mode else ''}")

    # 初始化模型
    model = AutoModel(**model_kwargs)

    # 预热
    print("模型预热...")
    if len(audio_files) > 0 and os.path.exists(audio_files[0]):
        model.generate(input=audio_files[0], cache={})

    # 正式测试
    results = []
    total_time = 0

    if batch_mode:
        # 批量处理模式
        print(f"开始批量处理 {len(audio_files)} 个音频文件...")
        start_time = time.time()

        batch_result = model.generate(
            input=audio_files,
            cache={},
            language="auto",
            use_itn=True,
            batch_size_s=60,
        )

        elapsed_time = time.time() - start_time
        total_time = elapsed_time

        for audio_path, res in zip(audio_files, batch_result):
            text = clean_asr_result(res["text"])
            results.append((audio_path, text, elapsed_time/len(audio_files)))
            print(f"文件: {os.path.basename(audio_path)}")
            print(f"识别结果: {text}")

        print(f"批量处理总耗时: {elapsed_time:.3f}秒")
        print(f"平均每个文件耗时: {elapsed_time/len(audio_files):.3f}秒")
    else:
        # 单个文件处理模式
        for audio_path in audio_files:
            if not os.path.exists(audio_path):
                print(f"警告：音频文件 {audio_path} 不存在，跳过")
                continue

            print(f"\n开始测试，音频文件: {audio_path}")
            start_time = time.time()

            result = model.generate(
                input=audio_path,
                cache={},
                language="auto",
                use_itn=True,
                batch_size_s=60,
            )

            elapsed_time = time.time() - start_time
            text = clean_asr_result(result[0]["text"])

            results.append((audio_path, text, elapsed_time))
            total_time += elapsed_time

            print(f"识别结果: {text}")
            print(f"处理耗时: {elapsed_time:.3f}秒")

    return results, total_time


def main():
    print("\n=== 环境诊断 ===")
    print(f"PyTorch版本: {torch.__version__}")
    print(f"CUDA可用: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"当前设备: {torch.cuda.current_device()}")
        print(f"设备名称: {torch.cuda.get_device_name(0)}")

    parser = argparse.ArgumentParser(description="测试FunASR GPU与非GPU性能")
    parser.add_argument("--audio_dir", default="audio_files", help="包含音频文件的目录路径")
    args = parser.parse_args()

    # 指定本地模型路径
    model_path = "SenseVoiceSmall"

    # 获取指定目录下所有asr_test开头的wav文件
    audio_files = sorted(glob.glob(os.path.join(args.audio_dir, "asr_test*")))

    if not audio_files:
        print(f"错误：在目录 {args.audio_dir} 中未找到任何asr_test*.wav音频文件")
        return

    print("\n找到以下音频文件将用于测试:")
    for f in audio_files:
        print(f" - {f}")

    # 单个文件处理测试
    print("\n=== 单个文件处理测试 ===")
    print("\n=== GPU测试 ===")
    gpu_results, gpu_total_time = test_asr_performance(audio_files, model_path, use_gpu=True)
    print(f"\nGPU总耗时: {gpu_total_time:.3f}秒")

    print("\n=== CPU测试 ===")
    cpu_results, cpu_total_time = test_asr_performance(audio_files, model_path, use_gpu=False)
    print(f"\nCPU总耗时: {cpu_total_time:.3f}秒")

    # 批量处理测试
    print("\n=== 批量处理测试 ===")
    print("\n=== GPU批量处理 ===")
    gpu_batch_results, gpu_batch_time = test_asr_performance(audio_files, model_path, use_gpu=True, batch_mode=True)

    print("\n=== CPU批量处理 ===")
    cpu_batch_results, cpu_batch_time = test_asr_performance(audio_files, model_path, use_gpu=False, batch_mode=True)

    # 性能对比
    print("\n=== 性能对比 ===")
    print("\n[单个文件处理模式]")
    print(f"GPU加速比: {cpu_total_time/gpu_total_time:.2f}x")
    print(f"总时间节省: {cpu_total_time-gpu_total_time:.3f}秒 (减少{(1-gpu_total_time/cpu_total_time)*100:.1f}%)")

    print("\n[批量处理模式]")
    print(f"GPU批量加速比: {cpu_batch_time/gpu_batch_time:.2f}x")
    print(f"GPU批量处理效率: {len(audio_files)/gpu_batch_time:.2f} 文件/秒")
    print(f"CPU批量处理效率: {len(audio_files)/cpu_batch_time:.2f} 文件/秒")

    # 输出详细结果对比
    print("\n=== 详细结果 ===")
    print(f"{'模式':<10} | {'文件':<15} | {'设备':<6} | {'时间(秒)':<12} | {'加速比':<8}")
    print("-" * 70)

    # 单个处理结果
    for (gpu_file, gpu_text, gpu_time), (cpu_file, cpu_text, cpu_time) in zip(gpu_results, cpu_results):
        if gpu_file == cpu_file:
            ratio = cpu_time / gpu_time
            print(f"{'单个':<10} | {os.path.basename(gpu_file):<15} | {'GPU':<6} | {gpu_time:<12.3f} | {ratio:.2f}x")
            print(f"{'单个':<10} | {os.path.basename(cpu_file):<15} | {'CPU':<6} | {cpu_time:<12.3f} | {'-':<8}")

    if len(gpu_batch_results) > 0 and len(cpu_batch_results) > 0:
        avg_gpu_time = sum([t for _, _, t in gpu_batch_results])/len(gpu_batch_results)
        avg_cpu_time = sum([t for _, _, t in cpu_batch_results])/len(cpu_batch_results)
        ratio = avg_cpu_time / avg_gpu_time
        print(f"{'批量':<10} | {'多文件':<12} | {'GPU':<6} | {avg_gpu_time:<12.3f} | {ratio:.2f}x")
        print(f"{'批量':<10} | {'多文件':<12} | {'CPU':<6} | {avg_cpu_time:<12.3f} | {'-':<8}")


if __name__ == "__main__":
    main()

### 测试结果
模式         | 文件              | 设备     | 时间(秒)        | 加速比
----------------------------------------------------------------------
单个         | asr_test.wav    | GPU    | 0.052        | 4.54x
单个         | asr_test.wav    | CPU    | 0.234        | -
单个         | asr_test1.wav   | GPU    | 0.048        | 3.45x
单个         | asr_test1.wav   | CPU    | 0.166        | -
单个         | asr_test2.wav   | GPU    | 0.048        | 4.05x
单个         | asr_test2.wav   | CPU    | 0.195        | -
单个         | asr_test3.wav   | GPU    | 0.052        | 4.97x
单个         | asr_test3.wav   | CPU    | 0.261        | -
单个         | asr_test4.wav   | GPU    | 0.048        | 3.76x
单个         | asr_test4.wav   | CPU    | 0.179        | -
单个         | asr_test5.wav   | GPU    | 0.050        | 4.41x
单个         | asr_test5.wav   | CPU    | 0.220        | -
单个         | asr_test6.mp3   | GPU    | 0.056        | 5.62x
单个         | asr_test6.mp3   | CPU    | 0.313        | -
单个         | asr_test7.mp3   | GPU    | 0.079        | 11.50x
单个         | asr_test7.mp3   | CPU    | 0.907        | -
单个         | asr_test8.mp3   | GPU    | 0.207        | 11.75x
单个         | asr_test8.mp3   | CPU    | 2.431        | -
批量         | 多文件          | GPU    | 0.068        | 8.03x
批量         | 多文件          | CPU    | 0.542        | -
